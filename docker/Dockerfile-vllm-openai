# docker/Dockerfile-vllm-openai
FROM pytorch/pytorch:2.1.2-cuda12.1-cudnn8-devel
# FROM nvidia/cuda:12.2.0-devel-ubuntu22.04

# Install the timezone data package
#RUN apt-get update && DEBIAN_FRONTEND="noninteractive" \
#        apt-get install -y tzdata && \
#        rm -rf /var/lib/apt/lists/*

# 装相关依赖包
# RUN apt-get update && apt-get -y install python3.10 \
RUN apt-get update -y && apt-get install -y python3.10 \
    python3-pip openmpi-bin libopenmpi-dev git

# Set the timezone to Asia/Shanghai
ENV TZ=Asia/Shanghai
# Copy the local time file to the container
RUN cp /usr/share/zoneinfo/$TZ /etc/localtime \
        && echo $TZ > /etc/timezone

RUN apt-get update && DEBIAN_FRONTEND="noninteractive" \
    apt-get install -y git tmux htop vim git-lfs pip wget openssl && \
    rm -rf /var/lib/apt/lists/*

# RUN pip install -U flash-attn --no-build-isolation --use-pep517
#RUN pip install --no-cache-dir \
#        torch==2.4.0  torchvision==0.19.0  torchaudio==2.4.0 \
#        --index-url https://download.pytorch.org/whl/cu121

RUN pip install --no-cache-dir  \
        -i https://pypi.tuna.tsinghua.edu.cn/simple  \
        --trusted-host pypi.tuna.tsinghua.edu.cn \
        bitsandbytes==0.42.0 \
        transformers>=4.45.2 \
        peft>=0.11.1  \
        accelerate>=0.30.1  \
        deepspeed==0.14.0 \
        datasets>=2.16.0 \
        numpy  \
        trl>=0.8.6 \
        gradio>=4.0.0 \
        tiktoken \
        transformers_stream_generator \
        datamodel_code_generator \
        sentence_transformers \
        fastapi \
        prometheus_client \
        starlette \
        triton==2.3.0


RUN pip install --no-cache-dir  \
    vllm==0.5.5 \
    vllm-flash-attn==2.6.1 \
    vllm_nccl_cu12==2.18.1.0.4.0


RUN wget https://cdn-media.hf-mirror.com/frpc-gradio-0.2/frpc_linux_amd64 && \
    mv frpc_linux_amd64 frpc_linux_amd64_v0.2 && \
    mv frpc_linux_amd64_v0.2 /opt/conda/lib/python3.10/site-packages/gradio/ && \
    chmod 755 /opt/conda/lib/python3.10/site-packages/gradio/frpc_linux_amd64_v0.2

WORKDIR /app
COPY examples/vllm_based_web_gradio.py /app
COPY examples/openai_api_server.py /app
COPY examples/openai_protocol.py /app
COPY examples/openai_serving_chat.py /app
COPY examples/openai_utils.py /app

RUN chmod u+x /app/vllm_based_web_gradio.py
RUN chmod u+x /app/openai_api_server.py

RUN openssl req -x509 -days 3650 -nodes -newkey rsa  \
    -keyout ./key.pem -out ./cert.pem -subj "/CN=ChatTTS"






