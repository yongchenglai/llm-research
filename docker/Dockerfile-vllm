# Dockerfile-llama
FROM pytorch/pytorch:2.1.2-cuda12.1-cudnn8-devel

# Install the timezone data package
RUN apt-get update && DEBIAN_FRONTEND="noninteractive" \
        apt-get install -y tzdata && \
        rm -rf /var/lib/apt/lists/*

# Set the timezone to Asia/Shanghai
ENV TZ=Asia/Shanghai
# Copy the local time file to the container
RUN cp /usr/share/zoneinfo/$TZ /etc/localtime \
        && echo $TZ > /etc/timezone

RUN apt-get update && DEBIAN_FRONTEND="noninteractive" \
    apt-get install -y git tmux htop vim git-lfs pip wget && \
    rm -rf /var/lib/apt/lists/*

RUN pip install flash-attn --no-build-isolation --use-pep517

RUN pip install --no-cache-dir \
    -i https://pypi.tuna.tsinghua.edu.cn/simple \
    --trusted-host pypi.tuna.tsinghua.edu.cn \
    bitsandbytes==0.43.1 \
    accelerate==0.30.1 \
    numpy==1.26.4 \
    gekko==1.0.6 \
    pandas \
    scipy \
    sentencepiece==0.2.0 \
    datasets \
    evaluate \
    pytest \
    peft==0.10.0 \
    transformers==4.43.3 \
    transformers_stream_generator \
    deepspeed==0.14.0 \
    scikit-learn \
    torch==2.1.2 \
    torchvision \
    pytorchvideo \
    torchdata \
    torchaudio \
    tensorboard \
    gradio \
    packaging \
    tqdm \
    rouge \
    jieba \
    fuzzywuzzy \
    einops \
    tiktoken \
    xformers \
    streamlit \
    cpm_kernels \
    decord>=0.6.0 \
    chainlit \
    autoawq autoawq-kernels \
    auto_gptq optimum \
    datamodel_code_generator


# RUN pip install --no-cache-dir vllm==0.6.1
RUN pip install --no-cache-dir vllm==0.5.5

RUN wget https://cdn-media.hf-mirror.com/frpc-gradio-0.2/frpc_linux_amd64 && \
    mv frpc_linux_amd64 frpc_linux_amd64_v0.2 && \
    mv frpc_linux_amd64_v0.2 /opt/conda/lib/python3.10/site-packages/gradio/ && \
    chmod 755 /opt/conda/lib/python3.10/site-packages/gradio/frpc_linux_amd64_v0.2

#设置工作目录
WORKDIR /app

COPY examples/vllm_based_chat_gradio.py /app
RUN chmod u+x /app/vllm_based_chat_gradio.py

#开启7860端口
EXPOSE 7860

#设置启动命令
#ENTRYPOINT ["python", "llama_chat_gradio.py", \
#            "--model_name_or_path=/workspace/models"]
